# ImplementaciÃ³n de Pandas y NumPy - AnÃ¡lisis Avanzados

## ğŸ“¦ InstalaciÃ³n

Pandas y NumPy ya estÃ¡n incluidos en `requirements.txt`. Para instalar:

```bash
pip install -r requirements.txt
```

O solo las librerÃ­as de anÃ¡lisis:
```bash
pip install pandas numpy
```

---

## ğŸ¯ DÃ³nde y CÃ³mo se ImplementÃ³

### 1. **Archivo Principal: `TelemetriaDelancer/panaccess/analytics.py`**

Este archivo contiene todas las funciones de anÃ¡lisis, organizadas en tres secciones:

#### **SecciÃ³n 1: AnÃ¡lisis Simples (Django ORM)**
- `get_top_channels()` - Top canales mÃ¡s vistos
- `get_channel_audience()` - Audiencia por canal
- `get_peak_hours_by_channel()` - Horarios pico
- `get_average_duration_by_channel()` - DuraciÃ³n promedio
- `get_temporal_analysis()` - AnÃ¡lisis temporal
- `get_geographic_analysis()` - AnÃ¡lisis geogrÃ¡fico

**Â¿Por quÃ© Django ORM?**
- Aprovecha Ã­ndices de base de datos
- Muy eficiente en memoria
- No requiere cargar datos en RAM

#### **SecciÃ³n 2: AnÃ¡lisis Complejos (Raw SQL)**
- `get_day_over_day_comparison()` - ComparaciÃ³n dÃ­a a dÃ­a
- `get_anomaly_detection()` - DetecciÃ³n de anomalÃ­as

**Â¿Por quÃ© Raw SQL?**
- Funciones de ventana (LAG, LEAD)
- CTEs complejas
- Optimizado para PostgreSQL

#### **SecciÃ³n 3: AnÃ¡lisis Avanzados (Pandas + NumPy)** â­ NUEVO

Estas son las funciones que aprovechan Pandas y NumPy:

---

## ğŸ”¬ Funciones con Pandas/NumPy

### 1. **`get_cohort_analysis_pandas()`**
**UbicaciÃ³n:** LÃ­nea ~334

**Â¿QuÃ© hace?**
- Analiza comportamiento de grupos de usuarios por fecha de inicio
- Calcula retenciÃ³n y engagement por cohorte
- Identifica patrones de uso a lo largo del tiempo

**Â¿Por quÃ© Pandas?**
- Agrupaciones complejas por mÃºltiples dimensiones
- Transformaciones de fechas avanzadas
- CÃ¡lculos de retenciÃ³n que requieren operaciones secuenciales

**Ejemplo de uso:**
```python
from TelemetriaDelancer.panaccess.analytics import get_cohort_analysis_pandas
from datetime import datetime, timedelta

end_date = datetime.now()
start_date = end_date - timedelta(days=90)

cohort_data = get_cohort_analysis_pandas(start_date, end_date)
# Retorna: {
#   "data": [...],  # Datos de cohortes
#   "summary": {
#     "total_cohorts": 3,
#     "total_users": 1500,
#     "avg_cohort_size": 500
#   }
# }
```

---

### 2. **`get_correlation_analysis()`**
**UbicaciÃ³n:** LÃ­nea ~390

**Â¿QuÃ© hace?**
- Analiza correlaciones entre variables (duraciÃ³n, frecuencia, canales, etc.)
- Identifica relaciones estadÃ­sticas entre mÃ©tricas
- Genera matriz de correlaciones y estadÃ­sticas descriptivas

**Â¿Por quÃ© Pandas/NumPy?**
- CÃ¡lculo de correlaciones de Pearson
- Operaciones matriciales eficientes
- EstadÃ­sticas descriptivas avanzadas

**Ejemplo de uso:**
```python
from TelemetriaDelancer.panaccess.analytics import get_correlation_analysis

correlations = get_correlation_analysis()
# Retorna: {
#   "correlation_matrix": {...},
#   "descriptive_stats": {...},
#   "insights": {
#     "strongest_correlation": {
#       "variable1": "total_watch_time",
#       "variable2": "unique_channels",
#       "correlation": 0.85,
#       "strength": "fuerte"
#     }
#   }
# }
```

---

### 3. **`get_time_series_analysis()`**
**UbicaciÃ³n:** LÃ­nea ~460

**Â¿QuÃ© hace?**
- Analiza tendencias temporales
- Calcula media mÃ³vil
- Genera pronÃ³sticos simples usando regresiÃ³n lineal
- Identifica direcciÃ³n de tendencia (creciente/decreciente/estable)

**Â¿Por quÃ© Pandas/NumPy?**
- ManipulaciÃ³n de series temporales
- CÃ¡lculo de media mÃ³vil
- RegresiÃ³n lineal con `np.polyfit()`
- GeneraciÃ³n de fechas futuras para pronÃ³stico

**Ejemplo de uso:**
```python
from TelemetriaDelancer.panaccess.analytics import get_time_series_analysis

# AnÃ¡lisis de un canal especÃ­fico con pronÃ³stico de 7 dÃ­as
ts_analysis = get_time_series_analysis(
    channel="Canal Premium",
    forecast_days=7
)
# Retorna: {
#   "historical_data": [...],  # Datos histÃ³ricos con media mÃ³vil
#   "forecast": [...],  # PronÃ³stico para prÃ³ximos 7 dÃ­as
#   "statistics": {
#     "mean": 1250.5,
#     "std": 320.2,
#     "trend_slope": 15.3,
#     "trend_direction": "creciente"
#   }
# }
```

---

### 4. **`get_user_segmentation_analysis()`**
**UbicaciÃ³n:** LÃ­nea ~540

**Â¿QuÃ© hace?**
- Segmenta usuarios en grupos usando K-means clustering
- Identifica diferentes tipos de usuarios (ocasionales, regulares, activos, super activos)
- Analiza caracterÃ­sticas de cada segmento

**Â¿Por quÃ© NumPy?**
- ImplementaciÃ³n de K-means desde cero (sin sklearn)
- NormalizaciÃ³n de datos (z-score)
- CÃ¡lculos de distancias euclidianas
- AgrupaciÃ³n eficiente

**Ejemplo de uso:**
```python
from TelemetriaDelancer.panaccess.analytics import get_user_segmentation_analysis

# Segmentar en 4 grupos
segments = get_user_segmentation_analysis(n_segments=4)
# Retorna: {
#   "segments": [
#     {
#       "segment_id": 0,
#       "segment_name": "Usuarios Ocasionales",
#       "user_count": 450,
#       "percentage": 30.0,
#       "avg_metrics": {
#         "total_watch_time": 1200.5,
#         "avg_duration": 45.2,
#         "unique_channels": 3.1,
#         "total_views": 8.5
#       }
#     },
#     ...
#   ],
#   "total_users": 1500
# }
```

---

### 5. **`get_channel_performance_matrix()`**
**UbicaciÃ³n:** LÃ­nea ~620

**Â¿QuÃ© hace?**
- Crea matriz de rendimiento combinando mÃºltiples mÃ©tricas
- Calcula scores normalizados (0-100) para cada canal
- Genera ranking de canales por rendimiento
- Combina views, usuarios, duraciÃ³n, retenciÃ³n

**Â¿Por quÃ© Pandas?**
- Agregaciones complejas por mÃºltiples dimensiones
- CÃ¡lculo de mÃ©tricas derivadas
- NormalizaciÃ³n y scoring
- Ranking y ordenamiento

**Ejemplo de uso:**
```python
from TelemetriaDelancer.panaccess.analytics import get_channel_performance_matrix

performance = get_channel_performance_matrix()
# Retorna: {
#   "performance_matrix": [
#     {
#       "channel": "Canal Premium",
#       "total_views": 50000,
#       "unique_users": 5000,
#       "performance_score": 95.5,
#       "rank": 1
#     },
#     ...
#   ],
#   "summary": {
#     "total_channels": 25,
#     "top_channel": "Canal Premium",
#     "avg_performance_score": 65.3
#   }
# }
```

---

## ğŸ—ï¸ Arquitectura de ImplementaciÃ³n

### VerificaciÃ³n de Disponibilidad

```python
# Al inicio del archivo
try:
    import pandas as pd
    import numpy as np
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    logger.warning("Pandas/NumPy no estÃ¡n instalados...")

# FunciÃ³n helper
def _check_pandas():
    """Verifica si pandas estÃ¡ disponible."""
    if not PANDAS_AVAILABLE:
        raise ImportError("Pandas y NumPy son requeridos...")
```

### Flujo de Datos

```
1. Django ORM â†’ Carga datos filtrados (eficiente)
   â†“
2. ConversiÃ³n a DataFrame â†’ Solo campos necesarios
   â†“
3. Procesamiento con Pandas/NumPy â†’ AnÃ¡lisis estadÃ­stico
   â†“
4. ConversiÃ³n a Dict â†’ Retorno compatible con Django
```

### Optimizaciones Implementadas

1. **Carga Selectiva de Datos**
   - Solo carga campos necesarios con `.values()`
   - Filtros aplicados en BD antes de cargar

2. **Procesamiento Eficiente**
   - Uso de operaciones vectorizadas de NumPy
   - Agrupaciones optimizadas de Pandas
   - Evita loops de Python cuando es posible

3. **Manejo de Memoria**
   - No carga toda la tabla en memoria
   - Procesa en chunks cuando es necesario
   - Limpia DataFrames despuÃ©s de usar

---

## ğŸ“Š ComparaciÃ³n: Con vs Sin Pandas/NumPy

### AnÃ¡lisis de Correlaciones

**Sin Pandas (Solo SQL):**
```sql
-- Muy complejo, requiere mÃºltiples subconsultas
-- DifÃ­cil de mantener
-- Limitado a correlaciones simples
```

**Con Pandas:**
```python
# Simple y claro
correlation_matrix = user_stats[features].corr()
# Soporta mÃºltiples tipos de correlaciÃ³n
# FÃ¡cil de extender
```

### AnÃ¡lisis de Cohortes

**Sin Pandas:**
- RequerirÃ­a mÃºltiples consultas SQL complejas
- CÃ¡lculos de retenciÃ³n muy difÃ­ciles
- CÃ³digo difÃ­cil de mantener

**Con Pandas:**
- Una funciÃ³n clara y mantenible
- CÃ¡lculos de retenciÃ³n naturales
- FÃ¡cil de extender con nuevas mÃ©tricas

---

## ğŸš€ Uso en Endpoints API

### Ejemplo: Endpoint de AnÃ¡lisis

```python
# En views.py
from TelemetriaDelancer.panaccess.analytics import (
    get_correlation_analysis,
    get_time_series_analysis,
    get_user_segmentation_analysis
)

class AnalyticsView(APIView):
    permission_classes = [AllowAny]
    
    def post(self, request):
        analysis_type = request.data.get('type')
        
        if analysis_type == 'correlation':
            result = get_correlation_analysis()
        elif analysis_type == 'time_series':
            channel = request.data.get('channel')
            result = get_time_series_analysis(channel=channel)
        elif analysis_type == 'segmentation':
            result = get_user_segmentation_analysis()
        else:
            return Response({"error": "Tipo de anÃ¡lisis no vÃ¡lido"}, 
                          status=400)
        
        return Response(result, status=200)
```

---

## âš ï¸ Consideraciones Importantes

### 1. **Rendimiento**
- Pandas es mÃ¡s lento que SQL para agregaciones simples
- Usar solo cuando SQL no es suficiente
- Cargar solo datos necesarios

### 2. **Memoria**
- DataFrames cargan datos en RAM
- Para tablas muy grandes, considerar procesamiento en chunks
- Limpiar DataFrames despuÃ©s de usar

### 3. **CuÃ¡ndo Usar Cada Enfoque**

| Tipo de AnÃ¡lisis | Enfoque Recomendado |
|-----------------|-------------------|
| Agregaciones simples | Django ORM |
| Funciones de ventana | Raw SQL |
| Correlaciones mÃºltiples | Pandas |
| Series temporales | Pandas |
| Clustering | NumPy/Pandas |
| Cohortes complejas | Pandas |

---

## ğŸ“ Resumen

### âœ… Implementado

1. **Pandas y NumPy agregados a requirements.txt**
2. **5 funciones avanzadas implementadas:**
   - AnÃ¡lisis de cohortes
   - AnÃ¡lisis de correlaciones
   - AnÃ¡lisis de series temporales
   - SegmentaciÃ³n de usuarios
   - Matriz de rendimiento de canales

3. **VerificaciÃ³n de disponibilidad** (graceful degradation)
4. **Optimizaciones de memoria y rendimiento**
5. **DocumentaciÃ³n completa**

### ğŸ¯ DÃ³nde EstÃ¡

- **Archivo principal:** `TelemetriaDelancer/panaccess/analytics.py`
- **LÃ­neas:** ~330-750 (funciones con Pandas/NumPy)
- **Dependencias:** `requirements.txt` (pandas>=2.0.0, numpy>=1.24.0)

### ğŸ”„ PrÃ³ximos Pasos

1. Instalar dependencias: `pip install -r requirements.txt`
2. Probar funciones individualmente
3. Crear endpoints API para exponer anÃ¡lisis
4. Agregar cachÃ© para anÃ¡lisis frecuentes (opcional)

---

**Documento creado:** 2025-12-31  
**Ãšltima actualizaciÃ³n:** 2025-12-31  
**VersiÃ³n:** 1.0

