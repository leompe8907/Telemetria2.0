# An√°lisis de Telemetr√≠a OTT - MergedTelemetricOTTDelancer

> **Nota de Compatibilidad:** Las consultas SQL en este documento est√°n optimizadas para **MySQL 8.0+ / MariaDB 10.2+**. Son compatibles con SQLite para desarrollo, pero funcionar√°n mejor en MySQL/MariaDB gracias a:
> - Mejor optimizaci√≥n de √≠ndices
> - Funciones de ventana (window functions) - MySQL 8.0+/MariaDB 10.2+
> - CTEs (Common Table Expressions) - MySQL 8.0+/MariaDB 10.2+
> - Mejor manejo de agregaciones complejas
> 
> **IMPORTANTE:** Los an√°lisis trabajan con datos de la base de datos local (`MergedTelemetricOTTDelancer`),
> NO consultan directamente a PanAccess. Los datos se obtienen de PanAccess mediante `telemetry_fetcher.py`
> y se almacenan localmente para an√°lisis eficientes.

## üìã √çndice

1. [Funciones Disponibles en `analytics.py`](#funciones-disponibles-en-analyticspy)
2. [An√°lisis de Consumo por Canal](#an√°lisis-de-consumo-por-canal)
3. [An√°lisis Temporal](#an√°lisis-temporal)
4. [An√°lisis por Dispositivo](#an√°lisis-por-dispositivo)
5. [An√°lisis Geogr√°fico](#an√°lisis-geogr√°fico)
6. [An√°lisis de Comportamiento](#an√°lisis-de-comportamiento)
7. [An√°lisis Comparativos](#an√°lisis-comparativos)
8. [An√°lisis Avanzados](#an√°lisis-avanzados)
9. [An√°lisis de Negocio](#an√°lisis-de-negocio)

---

## üîß Funciones Disponibles en `analytics.py`

Este documento explica los conceptos y tipos de an√°lisis disponibles. Las funciones reales implementadas en `TelemetriaDelancer/panaccess/analytics.py` son:

### Funciones de An√°lisis por Canal

1. **`get_top_channels(limit=10, start_date=None, end_date=None)`**
   - Retorna: `List[Dict]` con `channel`, `total_views`, `percentage`
   - Implementa: [Top Canales M√°s Vistos](#1-top-canales-m√°s-vistos)
   - Usa: Django ORM con agregaciones optimizadas

2. **`get_channel_audience(start_date=None, end_date=None)`**
   - Retorna: `List[Dict]` con `dataName`, `unique_devices`, `unique_users`, `total_views`, `total_watch_time`, `total_hours`
   - Implementa: [An√°lisis de Audiencia por Canal](#2-an√°lisis-de-audiencia-por-canal)
   - Usa: Django ORM con COUNT DISTINCT

3. **`get_peak_hours_by_channel(channel=None, start_date=None, end_date=None)`**
   - Retorna: `List[Dict]` con `dataName`, `timeDate`, `views`
   - Implementa: [Horarios Pico por Canal](#3-horarios-pico-por-canal)
   - Usa: Django ORM con agrupaci√≥n por canal y hora

4. **`get_average_duration_by_channel(start_date=None, end_date=None)`**
   - Retorna: `List[Dict]` con `dataName`, `avg_duration`, `total_views`, `total_watch_time`
   - Implementa: [Duraci√≥n Promedio por Canal](#4-duraci√≥n-promedio-por-canal)
   - Usa: Django ORM con AVG y SUM

### Funciones de An√°lisis Temporal

5. **`get_temporal_analysis(period='daily', start_date=None, end_date=None)`**
   - Par√°metros: `period` puede ser `'daily'`, `'weekly'`, o `'monthly'`
   - Retorna: `List[Dict]` con `period`, `views`
   - Implementa: [An√°lisis por Fecha](#5-an√°lisis-por-fecha-datadate)
   - Usa: Django ORM con `TruncDate`, `TruncWeek`, `TruncMonth` (MySQL/MariaDB) o Raw SQL (SQLite)

### Funciones de An√°lisis Avanzados (Raw SQL)

6. **`get_day_over_day_comparison(start_date=None, end_date=None)`**
   - Retorna: `List[Dict]` con `dataDate`, `daily_views`, `previous_day_views`, `day_over_day_change`
   - Implementa: [Comparaci√≥n Temporal](#17-comparaci√≥n-temporal)
   - Usa: Raw SQL con CTEs y funciones de ventana (LAG) - Requiere MySQL 8.0+ / MariaDB 10.2+
   - ‚ö†Ô∏è Requiere MySQL 8.0+ / MariaDB 10.2+ para funciones de ventana

7. **`get_anomaly_detection(threshold_std=3.0, start_date=None, end_date=None)`**
   - Retorna: `List[Dict]` con `dataDate`, `daily_views`, `average_views`, `standard_deviation`, `z_score`
   - Implementa: [An√°lisis de Anomal√≠as](#21-an√°lisis-de-anomal√≠as)
   - Usa: Raw SQL con CTEs y STDDEV_POP/STDDEV_SAMP
   - ‚ö†Ô∏è Requiere MySQL 8.0+ / MariaDB 10.2+ (usa STDDEV_SAMP en MySQL)

### Funciones de An√°lisis por Franjas Horarias

8. **`get_time_slot_analysis(start_date=None, end_date=None)`**
   - Retorna: `Dict` con `time_slots` (madrugada, ma√±ana, tarde, noche) y `summary`
   - Cada franja incluye: `total_seconds`, `total_hours` (redondeado a 2 decimales), `total_views`
   - Usa: Django ORM con `Case/When` para clasificar por franja horaria

### Funciones de Resumen General

9. **`get_general_summary(start_date=None, end_date=None)`**
   - Retorna: `Dict` con `total_views`, `active_users`, `unique_devices`, `unique_channels`, `total_watch_time_seconds`, `total_watch_time_hours`
   - Implementa: Resumen general del sistema
   - Usa: Django ORM con agregaciones

### Funciones de An√°lisis Geogr√°fico

10. **`get_geographic_analysis(start_date=None, end_date=None)`**
    - Retorna: `List[Dict]` con `whoisCountry`, `whoisIsp`, `total_views`, `unique_devices`, `unique_users`
    - Implementa: [An√°lisis por Pa√≠s](#10-an√°lisis-por-pa√≠s-whoiscountry)
    - Usa: Django ORM con agrupaci√≥n por pa√≠s e ISP

### Funciones de An√°lisis Avanzados (Pandas - Opcional)

11. **`get_cohort_analysis_pandas(start_date=None, end_date=None)`**
    - ‚ö†Ô∏è **Requiere Pandas/NumPy**
    - Retorna: `Dict` con `data` (cohortes), `summary` (total_cohorts, total_users)
    - Implementa: [An√°lisis de Cohortes](#22-an√°lisis-de-cohortes)
    - Usa: Pandas para an√°lisis de cohortes

12. **`get_correlation_analysis(start_date=None, end_date=None)`**
    - ‚ö†Ô∏è **Requiere Pandas/NumPy**
    - Retorna: `Dict` con `correlation_matrix`, `descriptive_stats`, `insights`
    - Implementa: [An√°lisis de Correlaciones](#19-an√°lisis-de-correlaciones)
    - Usa: Pandas para calcular matriz de correlaciones

13. **`get_time_series_analysis(channel=None, start_date=None, end_date=None, forecast_days=7)`**
    - ‚ö†Ô∏è **Requiere Pandas/NumPy**
    - Retorna: `Dict` con `historical_data`, `forecast`, `statistics`, `channel`
    - Implementa: [An√°lisis Predictivo](#20-an√°lisis-predictivo)
    - Usa: Pandas y NumPy para forecasting con regresi√≥n lineal

14. **`get_user_segmentation_analysis(start_date=None, end_date=None, n_segments=4)`**
    - ‚ö†Ô∏è **Requiere Pandas/NumPy**
    - Retorna: `Dict` con `segments`, `total_users`, `features_used`
    - Implementa: Segmentaci√≥n de usuarios usando K-means
    - Usa: NumPy para K-means clustering (implementaci√≥n simple)

15. **`get_channel_performance_matrix(start_date=None, end_date=None)`**
    - ‚ö†Ô∏è **Requiere Pandas/NumPy**
    - Retorna: `Dict` con `performance_matrix`, `summary`
    - Implementa: Matriz de rendimiento de canales con scoring
    - Usa: Pandas para calcular m√©tricas y scores normalizados

### Notas Importantes sobre las Funciones

- **Par√°metros opcionales**: Todas las funciones aceptan `start_date` y `end_date` opcionales para filtrar por rango de fechas
- **Filtros aplicados**: Se filtran autom√°ticamente registros donde los campos relevantes son `None` (ej: `dataName__isnull=False`)
- **Conversi√≥n de tiempo**: Los tiempos se almacenan en segundos (`dataDuration`) y se convierten a horas dividiendo por 3600.0
- **Redondeo**: Todos los valores de horas se redondean a 2 decimales
- **Base de datos local**: Todas las funciones trabajan con `MergedTelemetricOTTDelancer`, NO consultan PanAccess directamente
- **Compatibilidad**: Las funciones con Raw SQL requieren MySQL 8.0+ / MariaDB 10.2+ para funciones de ventana y CTEs
- **Pandas opcional**: Las funciones marcadas con ‚ö†Ô∏è requieren Pandas/NumPy instalados, si no est√°n disponibles lanzan `ImportError`

---

---

## üì∫ An√°lisis de Consumo por Canal

### 1. Top Canales M√°s Vistos

**¬øEn qu√© consiste?**
- Ranking de canales ordenados por n√∫mero total de visualizaciones (actionId=8)
- C√°lculo de porcentaje de participaci√≥n de cada canal respecto al total
- Identificaci√≥n de canales l√≠deres y nichos de mercado

**¬øC√≥mo se calcula?**
```sql
SELECT dataName, COUNT(*) as total_views, 
       (COUNT(*) * 100.0 / (SELECT COUNT(*) FROM merged_telemetric_ott)) as percentage
FROM merged_telemetric_ott
WHERE dataName IS NOT NULL
GROUP BY dataName
ORDER BY total_views DESC
```

**Impacto:**
- **Estrategia de contenido**: Identificar qu√© canales generan m√°s engagement
- **Negociaciones**: Datos para negociar mejores acuerdos con proveedores de contenido
- **Marketing**: Enfocar esfuerzos publicitarios en canales m√°s populares
- **ROI**: Optimizar inversi√≥n en contenido basado en demanda real

---

### 2. An√°lisis de Audiencia por Canal

**Funci√≥n implementada:** `get_channel_audience(start_date=None, end_date=None)`

**¬øEn qu√© consiste?**
- N√∫mero de dispositivos √∫nicos que consumen cada canal
- N√∫mero de usuarios √∫nicos (subscriberCode) por canal
- Total de horas vistas por canal
- Tasa de penetraci√≥n de cada canal en la base de usuarios

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** Usa Django ORM con COUNT DISTINCT y SUM
- **Consulta equivalente:**
```sql
SELECT dataName,
       COUNT(DISTINCT deviceId) as unique_devices,
       COUNT(DISTINCT subscriberCode) as unique_users,
       COUNT(*) as total_views,
       SUM(dataDuration) as total_watch_time
FROM merged_telemetric_ott
WHERE dataName IS NOT NULL
GROUP BY dataName
ORDER BY total_views DESC
```

**Retorna:**
```python
[
    {
        "dataName": "Canal Premium",
        "unique_devices": 1800,  # Count distinct de deviceId
        "unique_users": 2000,  # Count distinct de subscriberCode
        "total_views": 10000,  # Count de registros
        "total_watch_time": 900000.0,  # En segundos
        "total_hours": 250.0  # Calculado desde segundos, redondeado a 2 decimales
    },
    ...
]
```

**Notas:**
- Ordenado por `total_views` descendente
- `total_watch_time` est√° en segundos, `total_hours` se calcula dividiendo por 3600.0
- Solo incluye canales donde `dataName` no es `None`

**Impacto:**
- **Diversificaci√≥n**: Identificar si un canal tiene muchos views pero pocos usuarios (dependencia)
- **Crecimiento**: Canales con alto potencial de crecimiento de audiencia
- **Retenci√≥n**: Canales que atraen nuevos usuarios vs. canales que retienen existentes
- **Segmentaci√≥n**: Entender qu√© canales atraen a qu√© tipo de usuarios

---

### 3. Horarios Pico por Canal

**Funci√≥n implementada:** `get_peak_hours_by_channel(channel=None, start_date=None, end_date=None)`

**¬øEn qu√© consiste?**
- Identificar las franjas horarias (timeDate) con mayor consumo para cada canal
- Patrones diarios de visualizaci√≥n por canal
- Comparaci√≥n de horarios pico entre diferentes canales

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** Usa Django ORM con agrupaci√≥n por canal y hora
- **Consulta equivalente:**
```sql
SELECT dataName, timeDate, COUNT(*) as views
FROM merged_telemetric_ott
WHERE dataName IS NOT NULL AND timeDate IS NOT NULL
GROUP BY dataName, timeDate
ORDER BY dataName, views DESC
```

**Retorna:**
```python
[
    {
        "dataName": "Canal Premium",
        "timeDate": 20,  # Hora del d√≠a (0-23)
        "views": 500  # Count de registros en esa hora
    },
    ...
]
```

**Notas:**
- Si se proporciona `channel`, filtra solo ese canal
- Ordenado por `dataName` y luego por `views` descendente
- Solo incluye registros donde `dataName` y `timeDate` no son `None`

**Impacto:**
- **Programaci√≥n**: Optimizar horarios de programaci√≥n especial
- **Publicidad**: Maximizar impacto publicitario en horarios pico
- **Recursos**: Asignar recursos de servidor/CDN seg√∫n demanda horaria
- **Contenido**: Programar estrenos y contenido premium en horarios de mayor audiencia

---

### 4. Duraci√≥n Promedio por Canal

**Funci√≥n implementada:** `get_average_duration_by_channel(start_date=None, end_date=None)`

**¬øEn qu√© consiste?**
- Tiempo promedio de visualizaci√≥n (dataDuration) por canal
- Comparaci√≥n de duraci√≥n entre diferentes canales
- Identificaci√≥n de canales con mayor retenci√≥n de audiencia

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** Usa Django ORM con AVG, COUNT y SUM
- **Consulta equivalente:**
```sql
SELECT dataName,
       AVG(dataDuration) as avg_duration,
       COUNT(*) as total_views,
       SUM(dataDuration) as total_watch_time
FROM merged_telemetric_ott
WHERE dataName IS NOT NULL AND dataDuration IS NOT NULL
GROUP BY dataName
ORDER BY avg_duration DESC
```

**Retorna:**
```python
[
    {
        "dataName": "Canal Premium",
        "avg_duration": 1356.0,  # Promedio en segundos (float)
        "total_views": 10000,  # Count de registros
        "total_watch_time": 13560000.0  # Suma en segundos (float)
    },
    ...
]
```

**Notas:**
- Ordenado por `avg_duration` descendente
- `avg_duration` y `total_watch_time` est√°n en segundos
- Solo incluye canales donde `dataName` y `dataDuration` no son `None`

**Impacto:**
- **Calidad de contenido**: Canales con mayor duraci√≥n indican mejor contenido
- **Satisfacci√≥n**: Duraci√≥n como indicador de satisfacci√≥n del usuario
- **Monetizaci√≥n**: Canales con mayor duraci√≥n = m√°s oportunidades publicitarias
- **Renovaci√≥n de contenido**: Identificar canales que necesitan mejor contenido

---

## ‚è∞ An√°lisis Temporal

### 5. An√°lisis por Fecha (dataDate)

**Funci√≥n implementada:** `get_temporal_analysis(period='daily', start_date=None, end_date=None)`

**¬øEn qu√© consiste?**
- Consumo diario, semanal y mensual de contenido OTT
- Identificaci√≥n de tendencias temporales
- Comparaci√≥n de consumo entre diferentes per√≠odos (d√≠as, semanas, meses)

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** 
  - MySQL/MariaDB: Usa Django ORM con `TruncDate`, `TruncWeek`, `TruncMonth`
  - SQLite: Usa Raw SQL con `date()` y `strftime()` como fallback
- **Consulta equivalente:**
```sql
-- Diario (MySQL/MariaDB con Django ORM)
SELECT TruncDate(dataDate) as period, COUNT(*) as views
FROM merged_telemetric_ott
WHERE dataDate IS NOT NULL
GROUP BY period
ORDER BY period

-- Semanal (MySQL/MariaDB con Django ORM)
SELECT TruncWeek(dataDate) as period, COUNT(*) as views
FROM merged_telemetric_ott
WHERE dataDate IS NOT NULL
GROUP BY period
ORDER BY period

-- Mensual (MySQL/MariaDB con Django ORM)
SELECT TruncMonth(dataDate) as period, COUNT(*) as views
FROM merged_telemetric_ott
WHERE dataDate IS NOT NULL
GROUP BY period
ORDER BY period
```

**Retorna:**
```python
[
    {
        "period": "2025-01-01",  # Para daily (date object)
        "views": 5000  # Count de registros
    },
    ...
]
```

**Notas:**
- `period` puede ser `'daily'`, `'weekly'`, o `'monthly'`
- Para SQLite, usa Raw SQL como fallback (TruncDate no funciona en SQLite)
- Solo incluye registros donde `dataDate` no es `None`

**Impacto:**
- **Planificaci√≥n**: Anticipar demanda en fechas espec√≠ficas (festivos, eventos)
- **Capacidad**: Dimensionar infraestructura seg√∫n patrones temporales
- **Marketing**: Lanzar campa√±as en per√≠odos de mayor consumo
- **ROI**: Medir efectividad de campa√±as y promociones temporales

---

### 6. An√°lisis por Hora (timeDate)

**¬øEn qu√© consiste?**
- Distribuci√≥n de consumo por hora del d√≠a (0-23)
- Identificaci√≥n de horarios pico y valle
- Patrones de consumo seg√∫n hora del d√≠a

**¬øC√≥mo se calcula?**
```sql
SELECT timeDate, COUNT(*) as views
FROM merged_telemetric_ott
WHERE timeDate IS NOT NULL
GROUP BY timeDate
ORDER BY timeDate
```

**Impacto:**
- **Operaciones**: Optimizar recursos t√©cnicos seg√∫n demanda horaria
- **Soporte**: Prever picos de soporte t√©cnico en horarios de mayor uso
- **Contenido**: Programar contenido seg√∫n h√°bitos de visualizaci√≥n
- **Costos**: Optimizar costos de infraestructura (escalado autom√°tico)

---

### 7. An√°lisis de Sesiones

**¬øEn qu√© consiste?**
- Duraci√≥n promedio de sesiones de visualizaci√≥n
- Frecuencia de cambios de canal durante una sesi√≥n
- Patrones de consumo continuo vs. consumo fragmentado

**¬øC√≥mo se calcula?**
```sql
-- Sesiones por usuario/dispositivo
SELECT deviceId, subscriberCode,
       COUNT(*) as session_count,
       AVG(dataDuration) as avg_session_duration,
       MIN(timestamp) as first_view,
       MAX(timestamp) as last_view
FROM merged_telemetric_ott
WHERE dataDuration IS NOT NULL
GROUP BY deviceId, subscriberCode, DATE(timestamp)
```

**Impacto:**
- **UX**: Mejorar experiencia de usuario basada en patrones de sesi√≥n
- **Recomendaciones**: Sistema de recomendaciones basado en sesiones
- **Retenci√≥n**: Identificar factores que aumentan duraci√≥n de sesi√≥n
- **Monetizaci√≥n**: M√°s sesiones = m√°s oportunidades de monetizaci√≥n

---

## üì± An√°lisis por Dispositivo

### 8. Consumo por Dispositivo (deviceId)

**¬øEn qu√© consiste?**
- Identificar dispositivos m√°s activos en consumo de contenido
- Canales preferidos por tipo de dispositivo
- Patrones de uso espec√≠ficos por dispositivo

**¬øC√≥mo se calcula?**
```sql
SELECT deviceId,
       COUNT(*) as total_views,
       COUNT(DISTINCT dataName) as unique_channels,
       AVG(dataDuration) as avg_duration
FROM merged_telemetric_ott
WHERE deviceId IS NOT NULL
GROUP BY deviceId
ORDER BY total_views DESC
```

**Impacto:**
- **Desarrollo**: Priorizar desarrollo de apps para dispositivos m√°s usados
- **Soporte**: Enfocar soporte t√©cnico en dispositivos problem√°ticos
- **Marketing**: Campa√±as espec√≠ficas por tipo de dispositivo
- **Optimizaci√≥n**: Optimizar rendimiento para dispositivos m√°s populares

---

### 9. An√°lisis de Usuarios (subscriberCode/smartcardId)

**¬øEn qu√© consiste?**
- Identificar usuarios m√°s activos
- Canales preferidos por usuario individual
- Patrones de consumo personalizados

**¬øC√≥mo se calcula?**
```sql
SELECT subscriberCode,
       COUNT(*) as total_views,
       COUNT(DISTINCT dataName) as unique_channels,
       SUM(dataDuration) as total_watch_time
FROM merged_telemetric_ott
WHERE subscriberCode IS NOT NULL
GROUP BY subscriberCode
ORDER BY total_views DESC
```

**Impacto:**
- **Personalizaci√≥n**: Crear perfiles de usuario para recomendaciones
- **Retenci√≥n**: Identificar usuarios en riesgo de cancelaci√≥n
- **Upselling**: Ofertas personalizadas basadas en preferencias
- **Satisfacci√≥n**: Medir satisfacci√≥n individual y mejorar experiencia

---

## üåç An√°lisis Geogr√°fico

### 10. An√°lisis por Pa√≠s (whoisCountry)

**Funci√≥n implementada:** `get_geographic_analysis(start_date=None, end_date=None)`

**¬øEn qu√© consiste?**
- Distribuci√≥n de consumo de contenido por pa√≠s e ISP
- Canales m√°s populares por regi√≥n geogr√°fica
- Patrones de consumo regionales

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** Usa Django ORM con agrupaci√≥n por pa√≠s e ISP
- **Consulta equivalente:**
```sql
SELECT whoisCountry, whoisIsp,
       COUNT(*) as total_views,
       COUNT(DISTINCT deviceId) as unique_devices,
       COUNT(DISTINCT subscriberCode) as unique_users
FROM merged_telemetric_ott
WHERE whoisCountry IS NOT NULL
GROUP BY whoisCountry, whoisIsp
ORDER BY total_views DESC
```

**Retorna:**
```python
[
    {
        "whoisCountry": "US",
        "whoisIsp": "ISP Name",
        "total_views": 50000,  # Count de registros
        "unique_devices": 5000,  # Count distinct de deviceId
        "unique_users": 4500  # Count distinct de subscriberCode
    },
    ...
]
```

**Notas:**
- Agrupa por pa√≠s E ISP (combinaci√≥n de ambos)
- Ordenado por `total_views` descendente
- Solo incluye registros donde `whoisCountry` no es `None`

**Impacto:**
- **Expansi√≥n**: Identificar mercados con potencial de crecimiento
- **Contenido**: Adquirir contenido relevante para cada regi√≥n
- **Localizaci√≥n**: Traducir y localizar contenido seg√∫n demanda regional
- **Regulaci√≥n**: Cumplir con regulaciones locales de contenido

---

### 11. An√°lisis por ISP (whoisIsp)

**¬øEn qu√© consiste?**
- Distribuci√≥n de consumo por proveedor de internet
- An√°lisis de calidad de servicio por ISP
- Identificaci√≥n de problemas de conectividad por proveedor

**¬øC√≥mo se calcula?**
```sql
SELECT whoisIsp,
       COUNT(*) as total_views,
       AVG(dataDuration) as avg_duration,
       COUNT(DISTINCT deviceId) as unique_devices
FROM merged_telemetric_ott
WHERE whoisIsp IS NOT NULL
GROUP BY whoisIsp
ORDER BY total_views DESC
```

**Impacto:**
- **Partnerships**: Negociar acuerdos con ISPs principales
- **Optimizaci√≥n**: Optimizar CDN para ISPs espec√≠ficos
- **Soporte**: Identificar problemas de calidad por ISP
- **Marketing**: Campa√±as conjuntas con ISPs

---

### 12. An√°lisis por IP

**¬øEn qu√© consiste?**
- Distribuci√≥n geogr√°fica de direcciones IP
- Detecci√≥n de patrones an√≥malos o sospechosos
- An√°lisis de concentraci√≥n de consumo por IP

**¬øC√≥mo se calcula?**
```sql
SELECT ip,
       COUNT(*) as total_views,
       COUNT(DISTINCT deviceId) as unique_devices,
       whoisCountry, whoisIsp
FROM merged_telemetric_ott
WHERE ip IS NOT NULL
GROUP BY ip
ORDER BY total_views DESC
```

**Impacto:**
- **Seguridad**: Detectar uso an√≥malo o abusivo
- **Fraude**: Identificar posibles casos de fraude o compartir cuentas
- **Geolocalizaci√≥n**: Mejorar precisi√≥n de geolocalizaci√≥n
- **Optimizaci√≥n**: Optimizar routing seg√∫n ubicaci√≥n de IPs

---

## üéØ An√°lisis de Comportamiento

### 13. An√°lisis de Duraci√≥n (dataDuration)

**¬øEn qu√© consiste?**
- Distribuci√≥n estad√≠stica de duraciones de visualizaci√≥n
- Identificaci√≥n de sesiones cortas vs. largas
- An√°lisis de abandono temprano vs. visualizaci√≥n completa

**¬øC√≥mo se calcula?**
```sql
SELECT 
    CASE 
        WHEN dataDuration < 60 THEN 'Menos de 1 min'
        WHEN dataDuration < 300 THEN '1-5 min'
        WHEN dataDuration < 1800 THEN '5-30 min'
        WHEN dataDuration < 3600 THEN '30-60 min'
        ELSE 'M√°s de 1 hora'
    END as duration_category,
    COUNT(*) as count,
    AVG(dataDuration) as avg_duration
FROM merged_telemetric_ott
WHERE dataDuration IS NOT NULL
GROUP BY duration_category
```

**Impacto:**
- **Calidad**: Duraci√≥n como indicador de calidad de contenido
- **Engagement**: Medir nivel de engagement de usuarios
- **Optimizaci√≥n**: Mejorar contenido que tiene bajo tiempo de visualizaci√≥n
- **Monetizaci√≥n**: Contenido con mayor duraci√≥n = m√°s valor publicitario

---

### 14. An√°lisis de Cambios de Canal

**¬øEn qu√© consiste?**
- Frecuencia de cambios entre canales (actionId 7 ‚Üí 8)
- Identificaci√≥n de canales m√°s abandonados
- Canales con mayor retenci√≥n de audiencia

**¬øC√≥mo se calcula?**
```sql
-- Canales m√°s abandonados (actionId=8 con menor duraci√≥n)
SELECT dataName,
       COUNT(*) as abandonment_count,
       AVG(dataDuration) as avg_duration_before_abandon
FROM merged_telemetric_ott
WHERE actionId = 8 AND dataDuration IS NOT NULL
GROUP BY dataName
ORDER BY abandonment_count DESC
```

**Impacto:**
- **Contenido**: Mejorar canales con alta tasa de abandono
- **Programaci√≥n**: Ajustar programaci√≥n de canales problem√°ticos
- **UX**: Mejorar experiencia para reducir cambios de canal
- **Retenci√≥n**: Estrategias para aumentar retenci√≥n en canales espec√≠ficos

---

### 15. An√°lisis de Retenci√≥n

**¬øEn qu√© consiste?**
- Tasa de retenci√≥n por canal (usuarios que vuelven)
- Tiempo promedio antes de cambiar de canal
- Canales con mayor fidelidad de audiencia

**¬øC√≥mo se calcula?**
```sql
-- Retenci√≥n por canal (usuarios que vuelven al mismo canal)
SELECT dataName,
       COUNT(DISTINCT subscriberCode) as unique_users,
       COUNT(*) as total_views,
       COUNT(*) * 1.0 / COUNT(DISTINCT subscriberCode) as views_per_user
FROM merged_telemetric_ott
WHERE dataName IS NOT NULL AND subscriberCode IS NOT NULL
GROUP BY dataName
ORDER BY views_per_user DESC
```

**Impacto:**
- **Fidelizaci√≥n**: Estrategias para aumentar fidelidad a canales
- **Marketing**: Campa√±as de retenci√≥n para canales con baja fidelidad
- **Contenido**: Invertir en contenido que genera fidelidad
- **Suscripciones**: Canales con alta retenci√≥n = mejor valor de suscripci√≥n

---

## üìä An√°lisis Comparativos

### 16. Comparaci√≥n entre Canales

**¬øEn qu√© consiste?**
- Comparaci√≥n directa de m√©tricas entre diferentes canales
- An√°lisis competitivo de canales similares
- Benchmarking de rendimiento

**¬øC√≥mo se calcula?**
```sql
SELECT dataName,
       COUNT(*) as total_views,
       AVG(dataDuration) as avg_duration,
       COUNT(DISTINCT deviceId) as unique_devices,
       COUNT(DISTINCT subscriberCode) as unique_users
FROM merged_telemetric_ott
WHERE dataName IS NOT NULL
GROUP BY dataName
ORDER BY total_views DESC
```

**Impacto:**
- **Estrategia**: Identificar canales l√≠deres y oportunidades
- **Inversi√≥n**: Decidir d√≥nde invertir recursos de contenido
- **Competencia**: Entender posici√≥n competitiva de cada canal
- **Negociaci√≥n**: Datos para negociaciones con proveedores

---

### 17. Comparaci√≥n Temporal

**Funci√≥n implementada:** `get_day_over_day_comparison(start_date=None, end_date=None)`

**¬øEn qu√© consiste?**
- Comparaci√≥n de consumo d√≠a a d√≠a
- Identificaci√≥n de tendencias y patrones temporales
- An√°lisis de crecimiento o declive

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** Usa Raw SQL con CTEs y funciones de ventana (LAG)
- **Consulta equivalente:**
```sql
-- Comparaci√≥n d√≠a a d√≠a (MySQL 8.0+ / MariaDB 10.2+ optimizado con CTE)
WITH daily_stats AS (
    SELECT dataDate, COUNT(*) as daily_views
    FROM merged_telemetric_ott
    WHERE dataDate IS NOT NULL
    GROUP BY dataDate
)
SELECT dataDate,
       daily_views,
       LAG(daily_views) OVER (ORDER BY dataDate) as previous_day_views,
       daily_views - LAG(daily_views) OVER (ORDER BY dataDate) as day_over_day_change
FROM daily_stats
ORDER BY dataDate DESC
```

**Retorna:**
```python
[
    {
        "dataDate": "2025-01-15",  # date object
        "daily_views": 5000,  # Count de registros ese d√≠a
        "previous_day_views": 4800,  # Count del d√≠a anterior (LAG)
        "day_over_day_change": 200  # Diferencia absoluta
    },
    ...
]
```

**Notas:**
- ‚ö†Ô∏è **Requiere MySQL 8.0+ / MariaDB 10.2+** para funciones de ventana (LAG)
- Compatible con SQLite para desarrollo (con limitaciones)
- Solo incluye d√≠as con actividad
- Ordenado por `dataDate` descendente

**Impacto:**
- **Tendencias**: Identificar tendencias de crecimiento o declive
- **Eventos**: Medir impacto de eventos, promociones o campa√±as
- **Planificaci√≥n**: Anticipar demanda futura basada en tendencias
- **KPIs**: Establecer y monitorear KPIs temporales

---

### 18. Comparaci√≥n por Segmentos

**¬øEn qu√© consiste?**
- Comparaci√≥n de consumo entre diferentes segmentos (dispositivo, pa√≠s, ISP)
- An√°lisis de diferencias de comportamiento entre segmentos
- Identificaci√≥n de oportunidades por segmento

**¬øC√≥mo se calcula?**
```sql
-- Comparaci√≥n por pa√≠s
SELECT whoisCountry,
       COUNT(*) as total_views,
       AVG(dataDuration) as avg_duration,
       COUNT(DISTINCT dataName) as unique_channels
FROM merged_telemetric_ott
WHERE whoisCountry IS NOT NULL
GROUP BY whoisCountry
ORDER BY total_views DESC
```

**Impacto:**
- **Segmentaci√≥n**: Crear estrategias espec√≠ficas por segmento
- **Personalizaci√≥n**: Personalizar experiencia por segmento
- **Marketing**: Campa√±as segmentadas m√°s efectivas
- **Expansi√≥n**: Identificar segmentos con potencial de crecimiento

---

## üî¨ An√°lisis Avanzados

### 19. An√°lisis de Correlaciones

**¬øEn qu√© consiste?**
- Identificar correlaciones entre diferentes variables
- Correlaci√≥n entre hora y canal preferido
- Correlaci√≥n entre dispositivo y duraci√≥n de visualizaci√≥n
- Correlaci√≥n entre pa√≠s y preferencias de contenido

**¬øC√≥mo se calcula?**
```sql
-- Correlaci√≥n hora-canal
SELECT timeDate, dataName, COUNT(*) as views
FROM merged_telemetric_ott
WHERE timeDate IS NOT NULL AND dataName IS NOT NULL
GROUP BY timeDate, dataName
ORDER BY timeDate, views DESC
```

**Impacto:**
- **Insights**: Descubrir patrones ocultos en los datos
- **Predicci√≥n**: Mejorar predicciones basadas en correlaciones
- **Optimizaci√≥n**: Optimizar m√∫ltiples variables simult√°neamente
- **Estrategia**: Decisiones basadas en relaciones complejas

---

### 20. An√°lisis Predictivo (Series Temporales)

**Funci√≥n implementada:** `get_time_series_analysis(channel=None, start_date=None, end_date=None, forecast_days=7)`

**¬øEn qu√© consiste?**
- Predicci√≥n de consumo futuro basado en patrones hist√≥ricos
- An√°lisis de tendencias temporales con regresi√≥n lineal
- Pron√≥stico simple usando media m√≥vil y extrapolaci√≥n de tendencia

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** Usa Pandas y NumPy para an√°lisis de series temporales
- **Proceso:**
  1. Agrupa datos por d√≠a (`dataDate`)
  2. Calcula media m√≥vil de 7 d√≠as
  3. Calcula tendencia lineal usando regresi√≥n (`np.polyfit`)
  4. Genera pron√≥stico extrapolando la tendencia

**Retorna:**
```python
{
    "historical_data": [
        {
            "dataDate": "2025-01-01",
            "views": 5000,
            "moving_avg_7d": 4800.0,  # Media m√≥vil de 7 d√≠as
            "trend": 4950.0  # Valor de la l√≠nea de tendencia
        },
        ...
    ],
    "forecast": [
        {
            "dataDate": "2025-01-08",
            "forecast": 5200.0,  # Pron√≥stico basado en tendencia
            "moving_avg_forecast": 5000.0  # √öltima media m√≥vil
        },
        ...
    ],
    "statistics": {
        "mean": 5000.0,  # Promedio de visualizaciones diarias
        "std": 500.2,  # Desviaci√≥n est√°ndar
        "trend_slope": 50.5,  # Pendiente de la tendencia (cambio por d√≠a)
        "trend_direction": "creciente"  # "creciente", "decreciente", o "estable"
    },
    "channel": "Canal Premium"  # O "Todos los canales" si channel es None
}
```

**Notas:**
- ‚ö†Ô∏è **Requiere Pandas/NumPy** - Si no est√°n instalados, lanza `ImportError`
- `forecast_days` por defecto es 7 (puede ajustarse)
- Si se proporciona `channel`, filtra solo ese canal
- Si no hay datos, retorna: `{"message": "No hay datos para an√°lisis de series temporales"}`

**Impacto:**
- **Planificaci√≥n**: Anticipar demanda futura
- **Inversi√≥n**: Decidir inversiones en contenido basado en predicciones
- **Recursos**: Dimensionar infraestructura seg√∫n predicciones
- **Ventaja competitiva**: Anticipar tendencias del mercado

---

### 21. An√°lisis de Anomal√≠as

**Funci√≥n implementada:** `get_anomaly_detection(threshold_std=3.0, start_date=None, end_date=None)`

**¬øEn qu√© consiste?**
- Detecci√≥n de patrones inusuales o an√≥malos en el consumo
- Identificaci√≥n de picos an√≥malos de consumo
- Detecci√≥n de posibles problemas t√©cnicos o fraude

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** Usa Raw SQL con CTEs y STDDEV_POP/STDDEV_SAMP
- **Consulta equivalente:**
```sql
-- Detectar picos an√≥malos (consumo > threshold_std desviaciones est√°ndar)
WITH daily_counts AS (
    SELECT dataDate, COUNT(*) as daily_views
    FROM merged_telemetric_ott
    WHERE dataDate IS NOT NULL
    GROUP BY dataDate
),
stats AS (
    SELECT 
        AVG(daily_views) as avg_views,
        STDDEV_SAMP(daily_views) as stddev_views  -- STDDEV_SAMP en MySQL
    FROM daily_counts
)
SELECT dc.dataDate, dc.daily_views,
       s.avg_views as average_views,
       s.stddev_views as standard_deviation,
       ROUND((dc.daily_views - s.avg_views) / NULLIF(s.stddev_views, 0), 2) as z_score
FROM daily_counts dc
CROSS JOIN stats s
WHERE dc.daily_views > (s.avg_views + threshold_std * s.stddev_views)
ORDER BY dc.daily_views DESC
```

**Retorna:**
```python
[
    {
        "dataDate": "2025-01-15",  # date object
        "daily_views": 10000,  # Count de registros ese d√≠a
        "average_views": 5000.0,  # Promedio de visualizaciones diarias
        "standard_deviation": 1000.0,  # Desviaci√≥n est√°ndar
        "z_score": 5.0  # Z-score redondeado a 2 decimales
    },
    ...
]
```

**Notas:**
- ‚ö†Ô∏è **Requiere MySQL 8.0+ / MariaDB 10.2+** para CTEs y STDDEV
- `threshold_std` por defecto es 3.0 (puede ajustarse)
- En MySQL usa `STDDEV_SAMP` (ajustado autom√°ticamente en el c√≥digo)
- En SQLite usa `STDDEV` (ajustado autom√°ticamente en el c√≥digo)
- Solo retorna d√≠as donde `z_score > threshold_std`

**Impacto:**
- **Seguridad**: Detectar uso fraudulento o abusivo
- **Calidad**: Identificar problemas t√©cnicos r√°pidamente
- **Optimizaci√≥n**: Corregir problemas antes de que afecten a m√°s usuarios
- **Costos**: Prevenir costos innecesarios por anomal√≠as

---

### 22. An√°lisis de Cohortes

**Funci√≥n implementada:** `get_cohort_analysis_pandas(start_date=None, end_date=None)`

**¬øEn qu√© consiste?**
- An√°lisis de comportamiento de grupos de usuarios por fecha de inicio
- Evoluci√≥n del comportamiento de consumo por cohorte
- Comparaci√≥n de retenci√≥n entre diferentes cohortes

**¬øC√≥mo se calcula?**
- **Implementaci√≥n:** Usa Pandas para an√°lisis de cohortes
- **Consulta equivalente (concepto):**
```sql
-- Cohortes por mes de primer uso (concepto, implementado con Pandas)
-- Se agrupa por subscriberCode y se calcula el mes de primera actividad
-- Luego se analiza comportamiento por cohorte y per√≠odo
```

**Retorna:**
```python
{
    "data": [
        {
            "cohort_month": "2024-12",  # Per√≠odo de la cohorte
            "period": "2025-01",  # Per√≠odo de an√°lisis
            "subscriberCode": 500,  # Usuarios √∫nicos en ese per√≠odo
            "dataName": 25,  # Canales √∫nicos
            "dataDuration": 1250000.0,  # Tiempo total en segundos
            "cohort_size": 1000,  # Tama√±o inicial de la cohorte
            "retention_rate": 50.0  # Porcentaje de retenci√≥n
        },
        ...
    ],
    "summary": {
        "total_cohorts": 12,
        "total_users": 5000
    }
}
```

**Notas:**
- ‚ö†Ô∏è **Requiere Pandas/NumPy** - Si no est√°n instalados, lanza `ImportError`
- Usa Pandas para agrupar usuarios por mes de primera actividad
- Calcula retenci√≥n como: `(usuarios activos en per√≠odo / tama√±o inicial de cohorte) * 100`
- Solo incluye usuarios donde `subscriberCode` y `timestamp` no son `None`

**Impacto:**
- **Retenci√≥n**: Entender c√≥mo evoluciona la retenci√≥n por cohorte
- **Adquisici√≥n**: Mejorar estrategias de adquisici√≥n basadas en cohortes
- **LTV**: Calcular valor de vida del cliente por cohorte
- **Mejora continua**: Aprender de cohortes exitosas

---

## üíº An√°lisis de Negocio

### 23. An√°lisis de Ingresos (dataPrice)

**¬øEn qu√© consiste?**
- C√°lculo de ingresos generados por canal
- An√°lisis de monetizaci√≥n por contenido
- ROI por canal o tipo de contenido

**¬øC√≥mo se calcula?**
```sql
SELECT dataName,
       COUNT(*) as total_views,
       SUM(dataPrice) as total_revenue,
       AVG(dataPrice) as avg_price_per_view
FROM merged_telemetric_ott
WHERE dataPrice IS NOT NULL AND dataName IS NOT NULL
GROUP BY dataName
ORDER BY total_revenue DESC
```

**Impacto:**
- **Monetizaci√≥n**: Optimizar estrategias de monetizaci√≥n
- **Pricing**: Ajustar precios basado en demanda y valor percibido
- **ROI**: Medir retorno de inversi√≥n por canal
- **Decisiones**: Decidir qu√© contenido adquirir o producir

---

### 24. An√°lisis de Engagement

**¬øEn qu√© consiste?**
- M√©tricas de engagement por canal (tiempo total, frecuencia, retenci√≥n)
- Identificaci√≥n de contenido altamente engaging
- An√°lisis de factores que aumentan engagement

**¬øC√≥mo se calcula?**
```sql
SELECT dataName,
       COUNT(*) as total_views,
       SUM(dataDuration) as total_watch_time,
       COUNT(DISTINCT subscriberCode) as unique_users,
       AVG(dataDuration) as avg_duration,
       COUNT(*) * 1.0 / COUNT(DISTINCT subscriberCode) as views_per_user
FROM merged_telemetric_ott
WHERE dataName IS NOT NULL
GROUP BY dataName
ORDER BY total_watch_time DESC
```

**Impacto:**
- **Contenido**: Identificar qu√© contenido genera m√°s engagement
- **Estrategia**: Enfocar recursos en contenido de alto engagement
- **Retenci√≥n**: Engagement alto = mayor retenci√≥n de usuarios
- **Crecimiento**: Contenido engaging atrae nuevos usuarios

---

### 25. An√°lisis de Satisfacci√≥n

**¬øEn qu√© consiste?**
- Indicadores de satisfacci√≥n basados en duraci√≥n de visualizaci√≥n
- Canales con mayor satisfacci√≥n de usuarios
- Factores que correlacionan con satisfacci√≥n

**¬øC√≥mo se calcula?**
```sql
SELECT dataName,
       AVG(dataDuration) as avg_duration,
       COUNT(*) as total_views,
       COUNT(CASE WHEN dataDuration > 1800 THEN 1 END) * 100.0 / COUNT(*) as satisfaction_rate
FROM merged_telemetric_ott
WHERE dataName IS NOT NULL AND dataDuration IS NOT NULL
GROUP BY dataName
ORDER BY satisfaction_rate DESC
```

**Impacto:**
- **Calidad**: Mejorar calidad de contenido basado en satisfacci√≥n
- **Retenci√≥n**: Satisfacci√≥n alta = menor churn
- **Recomendaciones**: Recomendar contenido con alta satisfacci√≥n
- **Reputaci√≥n**: Construir reputaci√≥n basada en satisfacci√≥n del usuario

---

## üìà M√©tricas Clave Recomendadas (KPIs)

### M√©tricas de Consumo
- **Total de visualizaciones**: N√∫mero total de reproducciones
- **Tiempo total de visualizaci√≥n**: Suma de todas las duraciones
- **Duraci√≥n promedio**: Tiempo promedio por sesi√≥n
- **Usuarios activos**: Dispositivos/usuarios √∫nicos

### M√©tricas de Engagement
- **Sesiones por usuario**: Frecuencia de uso
- **Canales √∫nicos por usuario**: Diversidad de consumo
- **Tasa de retenci√≥n**: Porcentaje de usuarios que vuelven
- **Tiempo de sesi√≥n promedio**: Duraci√≥n promedio de sesi√≥n

### M√©tricas de Negocio
- **Ingresos por canal**: Monetizaci√≥n por contenido
- **Costo por adquisici√≥n**: Costo de adquirir nuevos usuarios
- **LTV (Lifetime Value)**: Valor de vida del cliente
- **Churn rate**: Tasa de cancelaci√≥n

---

## üéØ Priorizaci√≥n de An√°lisis

### Alta Prioridad (Impacto Inmediato)
1. **Top Canales M√°s Vistos** - Estrategia de contenido
2. **An√°lisis por Fecha** - Planificaci√≥n y capacidad
3. **Duraci√≥n Promedio por Canal** - Calidad de contenido
4. **An√°lisis de Engagement** - Retenci√≥n y crecimiento

### Media Prioridad (Impacto a Mediano Plazo)
5. **Horarios Pico por Canal** - Optimizaci√≥n de recursos
6. **An√°lisis por Dispositivo** - Desarrollo y soporte
7. **An√°lisis de Retenci√≥n** - Fidelizaci√≥n
8. **Comparaci√≥n entre Canales** - Estrategia competitiva

### Baja Prioridad (Impacto a Largo Plazo)
9. **An√°lisis Predictivo** - Planificaci√≥n avanzada
10. **An√°lisis de Cohortes** - Optimizaci√≥n continua
11. **An√°lisis de Correlaciones** - Insights avanzados
12. **An√°lisis de Anomal√≠as** - Seguridad y calidad

---

## üìù Notas de Implementaci√≥n

- Todos los an√°lisis deben considerar filtros por rango de fechas
- Los an√°lisis deben ser ejecutables de forma eficiente (usar √≠ndices)
- Considerar agregar cach√© para an√°lisis frecuentes
- Implementar paginaci√≥n para resultados grandes
- Exportar resultados a formatos est√°ndar (CSV, JSON, Excel)

---

## üöÄ Optimizaciones para MySQL/MariaDB

### √çndices Recomendados

Las consultas est√°n optimizadas para aprovechar los siguientes √≠ndices (ya creados en el modelo Django):

Los √≠ndices se crean autom√°ticamente mediante las migraciones de Django. Los √≠ndices definidos en `MergedTelemetricOTTDelancer` son:

- `idx_ott_actionid_timestamp`: Para filtros por actionId y timestamp
- `idx_ott_datadate_timedate`: Para an√°lisis por fecha y hora
- `idx_ott_dataname`: Para agrupaciones por canal
- `idx_ott_deviceid_datadate`: Para an√°lisis por dispositivo
- `idx_ott_recordid`: Para b√∫squedas por recordId

### √çndices Adicionales Recomendados para MySQL/MariaDB

```sql
-- √çndice compuesto para an√°lisis de usuarios (MySQL 8.0+ / MariaDB 10.2+)
CREATE INDEX idx_ott_subscriber_datadate ON merged_telemetric_ott(subscriberCode, dataDate);

-- √çndice para an√°lisis geogr√°fico
CREATE INDEX idx_ott_country_isp ON merged_telemetric_ott(whoisCountry, whoisIsp);

-- √çndice para an√°lisis de duraci√≥n
CREATE INDEX idx_ott_duration_dataname ON merged_telemetric_ott(dataDuration, dataName);
```

**Nota:** MySQL/MariaDB no soportan √≠ndices parciales (con WHERE) como PostgreSQL, pero los √≠ndices compuestos funcionan bien.

### Ventajas de MySQL 8.0+ / MariaDB 10.2+

1. **Mejor Optimizaci√≥n de Consultas**
   - Optimizador mejorado en versiones recientes
   - Mejor uso de √≠ndices m√∫ltiples
   - Estad√≠sticas de tablas para optimizaci√≥n

2. **Funciones de Ventana (Window Functions)**
   - `LAG()`, `LEAD()`, `ROW_NUMBER()` disponibles desde MySQL 8.0+ / MariaDB 10.2+
   - Mejor rendimiento en agregaciones complejas
   - Compatible con est√°ndar SQL

3. **CTEs (Common Table Expressions)**
   - Disponibles desde MySQL 8.0+ / MariaDB 10.2+
   - Mejor legibilidad y mantenibilidad
   - Optimizaci√≥n autom√°tica por el optimizador

4. **Tipos de Datos**
   - Tipos de fecha/hora precisos
   - JSON nativo (MySQL 5.7+ / MariaDB 10.2+)
   - Mejor manejo de NULLs

5. **Concurrencia**
   - Buen manejo de m√∫ltiples usuarios simult√°neos
   - Transacciones robustas
   - Locking eficiente

### Mejores Pr√°cticas para MySQL/MariaDB

1. **Usar EXPLAIN**
   ```sql
   EXPLAIN SELECT ...;
   ```
   - Verificar que se usen los √≠ndices correctos
   - Identificar cuellos de botella
   - MySQL 8.0+ incluye `EXPLAIN ANALYZE` (similar a PostgreSQL)

2. **ANALYZE TABLE Regular**
   ```sql
   ANALYZE TABLE merged_telemetric_ott;
   ```
   - Mantener estad√≠sticas actualizadas
   - Mejorar rendimiento del optimizador

3. **Particionamiento (Para Tablas Muy Grandes)**
   - Particionar por `dataDate` si la tabla crece mucho
   - Mejora significativa en consultas por rango de fechas
   - Disponible en MySQL 5.7+ / MariaDB 10.0+

4. **Usar Cache para An√°lisis Frecuentes**
   - El sistema ya implementa cache con Redis
   - Los resultados de an√°lisis se cachean autom√°ticamente
   - Ver `TelemetriaDelancer/mixins.py` para detalles

### Compatibilidad SQLite vs MySQL/MariaDB

| Funci√≥n | SQLite | MySQL 8.0+ / MariaDB 10.2+ | Nota |
|---------|--------|---------------------------|------|
| Formato fecha | `strftime('%Y-%m', date)` | `DATE_FORMAT(date, '%Y-%m')` o `YEAR(date), MONTH(date)` | MySQL m√°s eficiente |
| Desviaci√≥n est√°ndar | `STDDEV()` | `STDDEV_SAMP()` o `STDDEV_POP()` | MySQL m√°s preciso |
| Funciones ventana | Limitado | Completo (8.0+) | MySQL 8.0+ mucho mejor |
| CTEs | B√°sico | Avanzado (8.0+) | MySQL 8.0+ optimiza mejor |
| √çndices parciales | No | No | Solo PostgreSQL soporta WHERE en √≠ndices |

### Notas de Implementaci√≥n

Todas las consultas en este documento est√°n optimizadas para MySQL 8.0+ / MariaDB 10.2+. Para versiones anteriores:

- Reemplazar funciones de ventana por subconsultas
- Reemplazar `STDDEV_POP()` por `STDDEV_SAMP()` o c√°lculos manuales
- Simplificar CTEs si es necesario
- Usar principalmente Django ORM (funciona en todas las versiones)

---

**Documento creado:** 2025-12-31  
**√öltima actualizaci√≥n:** 2025-12-31  
**Versi√≥n:** 1.2 (Optimizado para MySQL 8.0+ / MariaDB 10.2+)

